# Trend Scanner Agent

–ê–≥–µ–Ω—Ç –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –Ω–æ–≤—ã—Ö —Ç—Ä–µ–Ω–¥–æ–≤ –∏ –±–∏–∑–Ω–µ—Å-–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π.

## –§—É–Ω–∫—Ü–∏–∏

- üîç **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ Google Trends** - –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
- üí¨ **–ê–Ω–∞–ª–∏–∑ Reddit** - –≤—ã—è–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
- üöÄ **–ü–∞—Ä—Å–∏–Ω–≥ Product Hunt** - –Ω–æ–≤—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã –∏ –∏–¥–µ–∏
- ü§ñ **AI –ê–Ω–∞–ª–∏–∑** - –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å –ø–æ–º–æ—â—å—é Claude
- üìä **Scoring** - –æ—Ü–µ–Ω–∫–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞ –∫–∞–∂–¥–æ–≥–æ —Ç—Ä–µ–Ω–¥–∞ (0-100)

## –£—Å—Ç–∞–Ω–æ–≤–∫–∞

```bash
cd agents/trend-scanner
pip install -r requirements.txt
```

## –ù–∞—Å—Ç—Ä–æ–π–∫–∞ API –∫–ª—é—á–µ–π

### Reddit API

1. –°–æ–∑–¥–∞–π—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ https://www.reddit.com/prefs/apps
2. –ü–æ–ª—É—á–∏—Ç–µ `client_id` –∏ `client_secret`
3. –î–æ–±–∞–≤—å—Ç–µ –≤ `.env`:

```bash
REDDIT_CLIENT_ID=your_client_id
REDDIT_CLIENT_SECRET=your_client_secret
```

### Product Hunt API (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

1. –°–æ–∑–¥–∞–π—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ https://www.producthunt.com/v2/oauth/applications
2. –ü–æ–ª—É—á–∏—Ç–µ access token
3. –î–æ–±–∞–≤—å—Ç–µ –≤ `.env`:

```bash
PRODUCT_HUNT_ACCESS_TOKEN=your_token
```

### Google Trends

Google Trends API –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –∫–ª—é—á–µ–π (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —á–µ—Ä–µ–∑ `pytrends`).

## –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```python
from agents.trend_scanner import TrendScannerAgent

# –°–æ–∑–¥–∞–µ–º –∞–≥–µ–Ω—Ç–∞
agent = TrendScannerAgent()

# –°–∫–∞–Ω–∏—Ä—É–µ–º —Ç—Ä–µ–Ω–¥—ã
trends = await agent.scan_trends(
    sources=["google_trends", "reddit", "product_hunt"],
    min_score=60,  # –¢–æ–ª—å–∫–æ —Ç—Ä–µ–Ω–¥—ã —Å score >= 60
    limit=20       # –¢–æ–ø-20 —Ç—Ä–µ–Ω–¥–æ–≤
)

# –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
for trend in trends:
    print(f"Score: {trend['score']}/100")
    print(f"Category: {trend['category']}")
    print(f"Pain: {trend['user_pain']}")
    print(f"Ideas: {trend['business_ideas']}")
    print()
```

### –ü–æ–ª—É—á–∏—Ç—å —Ç–æ–ø-—Ç—Ä–µ–Ω–¥—ã

```python
# –ü–æ–ª—É—á–∏—Ç—å —Ç–æ–ø-10 —Ç—Ä–µ–Ω–¥–æ–≤ –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–∫–∞–Ω–∞
top_trends = await agent.get_top_trends(limit=10)

# –§–∏–ª—å—Ç—Ä –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
tech_trends = await agent.get_top_trends(
    limit=10,
    category="technology"
)
```

### –ó–∞–ø—É—Å–∫ –∫–∞–∫ standalone —Å–∫—Ä–∏–ø—Ç

```bash
python -m agents.trend-scanner.agent
```

## –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
trend-scanner/
‚îú‚îÄ‚îÄ agent.py          # –û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å TrendScannerAgent
‚îú‚îÄ‚îÄ sources.py        # –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å API (Google, Reddit, PH)
‚îú‚îÄ‚îÄ analyzer.py       # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ —Å –ø–æ–º–æ—â—å—é LLM
‚îú‚îÄ‚îÄ scorer.py         # –û—Ü–µ–Ω–∫–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞ —Ç—Ä–µ–Ω–¥–æ–≤
‚îú‚îÄ‚îÄ requirements.txt  # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
‚îî‚îÄ‚îÄ README.md         # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
```

## Workflow

1. **–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤** - –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö
2. **–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è** - –æ—Ç–±–æ—Ä —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ç—Ä–µ–Ω–¥–æ–≤
3. **–ê–Ω–∞–ª–∏–∑ —Å LLM** - –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–≥–æ —Ç—Ä–µ–Ω–¥–∞
4. **Scoring** - –æ—Ü–µ–Ω–∫–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞ (0-100)
5. **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ** - –∑–∞–ø–∏—Å—å –≤ JSON —Ñ–∞–π–ª—ã
6. **–ü–µ—Ä–µ–¥–∞—á–∞** - –ª—É—á—à–∏–µ —Ç—Ä–µ–Ω–¥—ã ‚Üí Business Generator

## Scoring Algorithm

Score (0-100) —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –Ω–∞ –æ—Å–Ω–æ–≤–µ 5 —Ñ–∞–∫—Ç–æ—Ä–æ–≤:

| –§–∞–∫—Ç–æ—Ä | –í–µ—Å | –û–ø–∏—Å–∞–Ω–∏–µ |
|--------|-----|----------|
| **Popularity** | 30% | –ü–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å (votes, upvotes, interest) |
| **Engagement** | 25% | –í–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç—å (–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, —à–µ—Ä—ã) |
| **Market Size** | 20% | –†–∞–∑–º–µ—Ä —Ä—ã–Ω–∫–∞ (small/medium/large) |
| **Category** | 15% | –ö–∞—Ç–µ–≥–æ—Ä–∏—è (tech, health –∏–º–µ—é—Ç –≤—ã—à–µ score) |
| **Novelty** | 10% | –ù–æ–≤–∏–∑–Ω–∞ (–Ω–æ–≤—ã–µ —Ç—Ä–µ–Ω–¥—ã –ª—É—á—à–µ) |

## –ü—Ä–∏–º–µ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞

```json
{
  "source": "reddit",
  "subreddit": "SaaS",
  "title": "Frustrated with project management tools",
  "score": 85,
  "category": "productivity",
  "user_pain": "Users struggle with overly complex PM tools",
  "market_size": "large",
  "target_audience": "Freelancers and small teams",
  "business_ideas": [
    "Simplified PM tool with AI task automation",
    "No-code workflow builder for teams",
    "Smart deadline predictor based on past data"
  ],
  "reasoning": "Large market with clear pain points and low competition",
  "monetization": "subscription",
  "competition_level": "medium",
  "technical_complexity": "medium"
}
```

## –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö

–¢—Ä–µ–Ω–¥—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ `data/trends/`:

```
data/trends/
‚îú‚îÄ‚îÄ trends_20260206_143022.json  # Timestamped files
‚îú‚îÄ‚îÄ trends_20260206_150115.json
‚îî‚îÄ‚îÄ latest.json                   # –ü–æ—Å–ª–µ–¥–Ω–∏–π —Å–∫–∞–Ω
```

## –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

–õ–æ–≥–∏ –ø–∏—à—É—Ç—Å—è –≤ stdout —Å —É—Ä–æ–≤–Ω–µ–º `INFO`:

```
2026-02-06 14:30:22 - INFO - Trend Scanner Agent initialized
2026-02-06 14:30:22 - INFO - Starting trend scan from sources: ['google_trends', 'reddit']
2026-02-06 14:30:25 - INFO - Scanning Google Trends...
2026-02-06 14:30:27 - INFO - Found 15 trending searches from Google Trends
2026-02-06 14:30:28 - INFO - Scanning Reddit...
2026-02-06 14:30:31 - INFO - Found 24 posts from r/SaaS
2026-02-06 14:30:45 - INFO - Analyzed 32 trends successfully
2026-02-06 14:30:46 - INFO - Found 18 high-quality trends (score >= 60)
```

## –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ

### –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫

```python
# agents/trend-scanner/sources.py

class TwitterSource:
    async def get_trending_tweets(self, hashtags: List[str]):
        # –í–∞—à–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è
        pass

# agents/trend-scanner/agent.py

async def _scan_twitter(self):
    tweets = await self.twitter.get_trending_tweets(["#SaaS", "#AI"])
    return tweets
```

### –ù–∞—Å—Ç—Ä–æ–∏—Ç—å scoring

```python
# agents/trend-scanner/scorer.py

scorer = TrendScorer()

# –ò–∑–º–µ–Ω–∏—Ç—å –≤–µ—Å–∞
scorer.weights = {
    "popularity": 40,     # –ë–æ–ª—å—à–µ –≤–µ—Å –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏
    "engagement": 20,
    "market_size": 20,
    "category": 10,
    "novelty": 10
}
```

## –°—Ç–æ–∏–º–æ—Å—Ç—å

–ü—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ Claude Haiku –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:

- **–ê–Ω–∞–ª–∏–∑ 1 —Ç—Ä–µ–Ω–¥–∞**: ~1000 tokens = $0.0008
- **–°–∫–∞–Ω 50 —Ç—Ä–µ–Ω–¥–æ–≤**: ~$0.04
- **–ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π —Å–∫–∞–Ω**: ~$1.20/–º–µ—Å—è—Ü

–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–∞—Ç—á–∏–Ω–≥ –∏ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è –∑–∞—Ç—Ä–∞—Ç.

## Troubleshooting

### Google Trends –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç

```bash
pip install --upgrade pytrends
```

### Reddit 401 Unauthorized

–ü—Ä–æ–≤–µ—Ä—å—Ç–µ `REDDIT_CLIENT_ID` –∏ `REDDIT_CLIENT_SECRET` –≤ `.env`.

### Product Hunt no data

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è mock data –µ—Å–ª–∏ –Ω–µ—Ç —Ç–æ–∫–µ–Ω–∞. –ü–æ–ª—É—á–∏—Ç–µ —Ç–æ–∫–µ–Ω –Ω–∞ https://www.producthunt.com/v2/oauth/applications.

## TODO

- [ ] –î–æ–±–∞–≤–∏—Ç—å Twitter/X integration
- [ ] –î–æ–±–∞–≤–∏—Ç—å HackerNews integration
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ PostgreSQL
- [ ] –î–æ–±–∞–≤–∏—Ç—å –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—é —Ç—Ä–µ–Ω–¥–æ–≤
- [ ] Webhook —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ –Ω–æ–≤—ã—Ö —Ç–æ–ø-—Ç—Ä–µ–Ω–¥–∞—Ö
- [ ] Dashboard –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç—Ä–µ–Ω–¥–æ–≤

## –õ–∏—Ü–µ–Ω–∑–∏—è

MIT
